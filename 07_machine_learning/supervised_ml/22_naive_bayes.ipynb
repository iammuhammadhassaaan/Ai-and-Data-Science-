{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE Bayes algorithm\n",
    "\n",
    "Naive Bayes Algorithm is a classification algorithm based on Bayes Theorem. It is called naive because it assumes that the features in a dataset are independent of each other. This assumption is not true in real life but it simplifies the computation and gives good results in most of the cases.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "Bayes Theorem is a mathematical formula used for calculating conditional probability. It is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where A and B are events and P(B) != 0\n",
    "\n",
    "## Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes Algorithm is based on Bayes Theorem. It is defined as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1,x_2,...,x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "where y is the class variable and x1, x2, ..., xn are the features.\n",
    "\n",
    "The algorithm assumes that the features are independent of each other. So, the above equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1|y)P(x_2|y)...P(x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "The denominator is constant for a given input. So, the equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) \\propto P(x_1|y)P(x_2|y)...P(x_n|y)P(y)$$\n",
    "\n",
    "The class with the highest probability is the output of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets \n",
    "iris = load_iris()\n",
    "\n",
    "# split data into X and y \n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split into train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# model initalize \n",
    "model = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.75      1.00      0.86         9\n",
      "           2       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.91      0.90        30\n",
      "weighted avg       0.93      0.90      0.90        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  3  8]]\n"
     ]
    }
   ],
   "source": [
    "# model initalize \n",
    "model = MultinomialNB()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0 10  0]\n",
      " [ 0  9  0]\n",
      " [ 0 11  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muham\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muham\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# model initalize \n",
    "model = BernoulliNB()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
